{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0WhKdfgGNET4XB2pwdS/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaynyx/marvel/blob/main/task3_Metrics_and_Performance_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regression Related Metrics**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Regression models are another family of machine learning and statistical models, which are used to predict a continuous target values. They have a wide range of applications, from house price prediction, E-commerce pricing systems, weather forecasting, stock market prediction, to image super resolution, feature learning via auto-encoders, and image compression.\n",
        "\n",
        "\n",
        "Metrics used to evaluate these models should be able to work on a set of continuous values (with infinite cardinality), and are therefore slightly different from classification metrics."
      ],
      "metadata": {
        "id": "QBNooA2iJBBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MSE**\n",
        "\n",
        "“Mean squared error” is perhaps the most popular metric used for regression problems. It essentially finds the average squared error between the predicted and actual values.\n",
        "\n",
        "Let’s assume we have a regression model which predicts the price of houses in Seattle area (show them with ŷᵢ), and let’s say for each house we also have the actual price the house was sold for (denoted with yᵢ). Then the MSE can be calculated as:\n",
        "\n",
        "![MSE.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "Sometimes people use RMSE to have a metric with scale as the target values, which is essentially the square root of MSE.\n",
        "\n",
        "Looking at house pricing prediction, RMSE essentially shows what is the average deviation in your model predicted house prices from the target values (the prices the houses are sold for).\n"
      ],
      "metadata": {
        "id": "F0aqJagbKdbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "y_true=[1,2,3,4,5,6]\n",
        "y_pred=[0.5,2,3.4,5,5.5,6.9]\n",
        "print(\"Mean Squared Error:\",mean_squared_error(y_true,y_pred))\n",
        "print(\"Root Mean Squared Error\",np.sqrt(mean_squared_error(y_true,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8PMtxUlJDMX",
        "outputId": "ae6c25cc-cd6c-4bcf-8f84-319773f91e6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.4116666666666668\n",
            "Root Mean Squared Error 0.641612551830672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **MAE**\n",
        "\n",
        "Mean absolute error (or mean absolute deviation) is another metric which finds the average absolute distance between the predicted and target values. MAE is define as below:![MAE.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "T_CSaOmLMhFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "print(\"Mean Absolute Error:\",mean_absolute_error(y_true,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvF4gGxGMyQw",
        "outputId": "f199e4e9-4d29-4b15-f0cd-6459ef63f13c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Related Metrics**\n",
        "\n",
        "---\n",
        "Classification is one of the most widely used problems in machine learning with various industrial applications, from face recognition, Youtube video categorization, content moderation, medical diagnosis, to text classification, hate speech detection on Twitter.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZuE32zAkN0iK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**\n",
        "\n",
        "One of the key concept in classification performance is confusion matrix (AKA error matrix), which is a tabular visualization of the model predictions versus the ground-truth labels. Each row of confusion matrix represents the instances in a predicted class and each column represents the instances in an actual class."
      ],
      "metadata": {
        "id": "gxQTbiTmQV-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_true=[0, 1, 2, 2, 0, 1]\n",
        "y_pred=[0, 2, 2, 1, 0, 1]\n",
        "print(confusion_matrix(y_true,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldFejVPZRmQy",
        "outputId": "7627339d-a261-41e5-9ccd-1a7ac65227b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The row index represents the actual class, while the column index represents the predicted class.\n",
        "The element in the [0, 0] position (top-left) represents the number of instances where the actual class is 0 and the predicted class is 0. In this case, there are 2 such instances.\n",
        "The element in the [1, 1] position (middle-middle) represents the number of instances where the actual class is 1 and the predicted class is 1. There are 2 such instances.\n",
        "The element in the [2, 2] position (bottom-right) represents the number of instances where the actual class is 2 and the predicted class is 2. There is 1 such instance.\n",
        "The off-diagonal elements represent cases where the model made incorrect predictions. For example:\n",
        "\n",
        "The element in the [1, 2] position represents the number of instances where the actual class is 1, but the model predicted class 2. There is 1 such instance."
      ],
      "metadata": {
        "id": "FU7lDttFlT2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification accuracy**\n",
        "\n",
        "Classification accuracy is perhaps the simplest metrics one can imagine, and is defined as the number of correct predictions divided by the total number of predictions, multiplied by 100."
      ],
      "metadata": {
        "id": "iZhgL2SplVzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Classification Accuracy:\",accuracy_score(y_true,y_pred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dt6Vg_2lVBB",
        "outputId": "c76f180a-f5c6-446e-d8b2-f39a59a63150"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision**\n",
        "\n",
        "There are many cases in which classification accuracy is not a good indicator of your model performance. One of these scenarios is when your class distribution is imbalanced (one class is more frequent than others). In this case, even if you predict all samples as the most frequent class you would get a high accuracy rate, which does not make sense at all (because your model is not learning anything, and is just predicting everything as the top class). For example in our cat vs non-cat classification above, if the model predicts all samples as non-cat, it would result in a 1000/1100= 90.9%.\n",
        "\n",
        "Therefore we need to look at class specific performance metrics too. Precision is one of such metrics, which is defined as:\n",
        "\n",
        "Precision= True_Positive/ (True_Positive+ False_Positive)\n",
        "\n",
        "The precision of Cat and Non-Cat class in above example can be calculated as:\n",
        "\n",
        "Precision_cat= #samples correctly predicted cat/#samples predicted as cat = 90/(90+60) = 60%\n",
        "\n",
        "Precision_NonCat= 940/950= 98.9%\n",
        "\n",
        "\n",
        "**Recall**\n",
        "\n",
        "Recall is another important metric, which is defined as the fraction of samples from a class which are correctly predicted by the model. More formally:\n",
        "\n",
        "Recall= True_Positive/ (True_Positive+ False_Negative)\n",
        "\n",
        "Therefore, for our example above, the recall rate of cat and non-cat classes can be found as:\n",
        "\n",
        "Recall_cat= 90/100= 90%\n",
        "\n",
        "Recall_NonCat= 940/1000= 94%\n",
        "\n",
        "\n",
        "**F1 Score**\n",
        "\n",
        "Depending on application, you may want to give higher priority to recall or precision. But there are many applications in which both recall and precision are important. Therefore, it is natural to think of a way to combine these two into a single metric. One popular metric which combines precision and recall is called F1-score, which is the harmonic mean of precision and recall defined as:\n",
        "\n",
        "F1-score= 2*Precision*Recall/(Precision+Recall)\n",
        "\n",
        "So for our classification example with the confusion matrix in Figure 1, the F1-score can be calculated as:\n",
        "\n",
        "F1_cat= 2*0.6*0.9/(0.6+0.9)= 72%\n",
        "\n",
        "The generalized version of F-score is defined as below. As we can see F1-score is special case of F_ℬ when ℬ= 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "3ziy-b8UJnyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "print(\"Precision Score:\", precision_score(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p895USWwH_CS",
        "outputId": "2905f7c6-bfc2-4512-a297-161cc51dcdf3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "print(\"Recall Score:\", recall_score(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc-bcj3gJABs",
        "outputId": "8ae2cafd-d706-4bef-9df9-0159dad97a3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall Score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"F1 Score:\", f1_score(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5_Gnp-nJPKH",
        "outputId": "ce9e07ce-4366-4387-c7e5-95117bcf06ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.7272727272727272\n"
          ]
        }
      ]
    }
  ]
}