{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe94ruwFeMJNCcEtq0eeU2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaynyx/marvel/blob/main/task5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Implement KNN using sci-kit’s neighbors.KNeighborsClassifier for multiple\n",
        "suitable datasets**\n",
        "\n",
        "The feature matrix x is assigned the data from the Iris dataset. It contains measurements of sepal length, sepal width, petal length, and petal width for each iris sample.\n",
        "\n",
        "The target array y is assigned the target labels for each sample, which correspond to the species of the iris flower.\n",
        "\n",
        "test_size=0.2: Specifies that 20% of the data should be used for testing, while 80% is used for training.\n",
        "random_state=12: Sets the random seed for reproducibility.\n",
        "\n",
        "This line creates a K-Nearest Neighbors (KNN) classifier using KNeighborsClassifier from scikit-learn. It is configured to consider 3 nearest neighbors (n_neighbors=3)."
      ],
      "metadata": {
        "id": "7rjy-L47P9Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import preprocessing\n",
        "iris=datasets.load_iris()\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=12)\n",
        "knn=KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(x_train,y_train)\n",
        "knn.score(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JXOKFLcONZn",
        "outputId": "676e8fe9-14b6-423d-ec62-30c2d1cf75b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding the algorithm**\n",
        "\n",
        "For Classification: To classify a new data point, KNN finds the 'k' nearest data points from the training set (based on a similarity metric, typically Euclidean distance). These 'k' neighbors vote, and the class with the majority vote becomes the predicted class for the new data point.\n",
        "\n",
        "For Regression: To predict a numerical value, KNN finds the 'k' nearest data points and calculates the average (or weighted average) of their values. This average becomes the predicted value for the new data point."
      ],
      "metadata": {
        "id": "9gy4C7f7VRWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Implement KNN from scratch. Compare results with sci-kit’s built in method for different datasets.**\n",
        "\n",
        " In this section of code, NumPy (numpy) is imported for numerical operations, and Counter is imported to help with counting and finding the most common elements.\n",
        "\n",
        "The euclidean function is defined, which calculates the Euclidean distance between two data points x1 and x2 using NumPy. It's a measure of similarity or distance between data points.\n",
        "\n",
        "predict: Takes test data x_test and predicts the labels for each data point using the _predict method.\n",
        "_predict: This is a private helper method. For each data point in x_test, it calculates the Euclidean distance to all training data points, finds the k nearest neighbors, and returns the most common label among them.\n",
        "\n",
        "\n",
        "pred == y_test: This comparison generates a boolean array that indicates whether each prediction in pred matches the corresponding true label in y_test. For example, if pred contains [0, 1, 0] and y_test contains [0, 1, 2], the result of pred == y_test would be [True, True, False].\n",
        "\n",
        "np.sum(pred == y_test): The np.sum function is used to count the number of True values in the boolean array obtained from the previous step. This count represents the number of correct predictions made by the KNN classifier on the test data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8vBXpfDQQXpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "def euclidean(x1,x2):\n",
        "    return np.sqrt(np.sum((x1-x2)**2))\n",
        "class KNN:\n",
        "    def __init__(self,k=5):\n",
        "        self.k=k\n",
        "\n",
        "    def fit(self,x_train,y_train):\n",
        "        self.x_train=x_train\n",
        "        self.y_train=y_train\n",
        "\n",
        "    def predict(self,x_test):\n",
        "        predicted_labels=[self._predict(i) for i in x_test]\n",
        "        return np.array(predicted_labels)\n",
        "\n",
        "    def _predict(self,x_test):\n",
        "        distances = [euclidean(x_test,x_train) for x_train in self.x_train]\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "\n",
        "        most_common = Counter(k_nearest_labels).most_common()\n",
        "        return most_common[0][0]\n",
        "iris=datasets.load_iris()\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=12)\n",
        "knn = KNN(3)\n",
        "knn.fit(x_train,y_train)\n",
        "predictions=knn.predict(x_test)\n",
        "print(\"Accuracy:\",(np.sum(predictions==y_test)/len(y_test)))\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NruSgvCbNuJW",
        "outputId": "f7ea68c2-2301-41cb-b97f-b12a1b15b483"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    }
  ]
}